{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:39.106066Z","iopub.status.busy":"2024-04-28T07:28:39.105777Z","iopub.status.idle":"2024-04-28T07:28:45.987801Z","shell.execute_reply":"2024-04-28T07:28:45.986796Z","shell.execute_reply.started":"2024-04-28T07:28:39.106040Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","# Import libabries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import seaborn as sn\n","import pandas as pd\n","import torchvision\n","from torchvision import *\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.io import read_image\n","import torchvision.transforms as T\n","from torchvision import datasets, models, transforms\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","import matplotlib.pyplot as plt\n","import time\n","import copy\n","\n","from PIL import Image\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":2,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:45.989808Z","iopub.status.busy":"2024-04-28T07:28:45.989384Z","iopub.status.idle":"2024-04-28T07:28:46.047789Z","shell.execute_reply":"2024-04-28T07:28:46.046711Z","shell.execute_reply.started":"2024-04-28T07:28:45.989783Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":3,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.049756Z","iopub.status.busy":"2024-04-28T07:28:46.049111Z","iopub.status.idle":"2024-04-28T07:28:46.055786Z","shell.execute_reply":"2024-04-28T07:28:46.054905Z","shell.execute_reply.started":"2024-04-28T07:28:46.049720Z"},"trusted":true},"outputs":[],"source":["use_cuda = torch.cuda.is_available()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.058514Z","iopub.status.busy":"2024-04-28T07:28:46.057950Z","iopub.status.idle":"2024-04-28T07:28:46.065100Z","shell.execute_reply":"2024-04-28T07:28:46.064115Z","shell.execute_reply.started":"2024-04-28T07:28:46.058488Z"},"trusted":true},"outputs":[],"source":["train_dir = '/kaggle/input/ima205-challenge-2024/Train/Train'\n","train_data = '/kaggle/input/ima205-challenge-2024/metadataTrain.csv'"]},{"cell_type":"code","execution_count":5,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.066574Z","iopub.status.busy":"2024-04-28T07:28:46.066174Z","iopub.status.idle":"2024-04-28T07:28:46.073439Z","shell.execute_reply":"2024-04-28T07:28:46.072491Z","shell.execute_reply.started":"2024-04-28T07:28:46.066547Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.075075Z","iopub.status.busy":"2024-04-28T07:28:46.074653Z","iopub.status.idle":"2024-04-28T07:28:46.084460Z","shell.execute_reply":"2024-04-28T07:28:46.083651Z","shell.execute_reply.started":"2024-04-28T07:28:46.075044Z"},"trusted":true},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, csv_file, img_dir, transform=None):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with ID and class labels.\n","            img_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied on a sample.\n","        \"\"\"\n","        img_labels = pd.read_csv(csv_file)\n","        self.img_labels = img_labels.drop(columns=['SEX','AGE','POSITION'])\n","        self.img_labels['CLASS'] = self.img_labels['CLASS'] - 1\n","\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, f\"{self.img_labels.iloc[idx, 0]}.jpg\")\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n"]},{"cell_type":"code","execution_count":7,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.086003Z","iopub.status.busy":"2024-04-28T07:28:46.085647Z","iopub.status.idle":"2024-04-28T07:28:46.145807Z","shell.execute_reply":"2024-04-28T07:28:46.144951Z","shell.execute_reply.started":"2024-04-28T07:28:46.085963Z"},"trusted":true},"outputs":[],"source":["dataset = CustomImageDataset(csv_file=train_data, img_dir=train_dir, transform=transform)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.147205Z","iopub.status.busy":"2024-04-28T07:28:46.146934Z","iopub.status.idle":"2024-04-28T07:28:46.152070Z","shell.execute_reply":"2024-04-28T07:28:46.151117Z","shell.execute_reply.started":"2024-04-28T07:28:46.147182Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["18998\n"]}],"source":["print(len(dataset))"]},{"cell_type":"code","execution_count":9,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.153545Z","iopub.status.busy":"2024-04-28T07:28:46.153292Z","iopub.status.idle":"2024-04-28T07:28:46.158516Z","shell.execute_reply":"2024-04-28T07:28:46.157524Z","shell.execute_reply.started":"2024-04-28T07:28:46.153523Z"},"trusted":true},"outputs":[],"source":["dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:46.162882Z","iopub.status.busy":"2024-04-28T07:28:46.162493Z","iopub.status.idle":"2024-04-28T07:28:47.537579Z","shell.execute_reply":"2024-04-28T07:28:47.536636Z","shell.execute_reply.started":"2024-04-28T07:28:46.162852Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 152MB/s] \n"]},{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model = models.resnet50(pretrained=True)\n","model"]},{"cell_type":"code","execution_count":11,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:47.539592Z","iopub.status.busy":"2024-04-28T07:28:47.538970Z","iopub.status.idle":"2024-04-28T07:28:47.544948Z","shell.execute_reply":"2024-04-28T07:28:47.543973Z","shell.execute_reply.started":"2024-04-28T07:28:47.539559Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of features from pre-trained model 2048\n"]}],"source":["num_features = model.fc.in_features \n","print('Number of features from pre-trained model', num_features)"]},{"cell_type":"code","execution_count":12,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:47.546817Z","iopub.status.busy":"2024-04-28T07:28:47.546295Z","iopub.status.idle":"2024-04-28T07:28:47.555553Z","shell.execute_reply":"2024-04-28T07:28:47.554492Z","shell.execute_reply.started":"2024-04-28T07:28:47.546778Z"},"trusted":true},"outputs":[],"source":["model.fc = nn.Linear(num_features, 8)  # 8 classes as per your requirement\n","softmax = nn.Softmax(dim=1)\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:47.557002Z","iopub.status.busy":"2024-04-28T07:28:47.556690Z","iopub.status.idle":"2024-04-28T07:28:47.563172Z","shell.execute_reply":"2024-04-28T07:28:47.562359Z","shell.execute_reply.started":"2024-04-28T07:28:47.556978Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":14,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:47.565014Z","iopub.status.busy":"2024-04-28T07:28:47.564354Z","iopub.status.idle":"2024-04-28T07:28:47.789312Z","shell.execute_reply":"2024-04-28T07:28:47.788493Z","shell.execute_reply.started":"2024-04-28T07:28:47.564979Z"},"trusted":true},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T07:28:47.790745Z","iopub.status.busy":"2024-04-28T07:28:47.790415Z","iopub.status.idle":"2024-04-28T08:57:35.787339Z","shell.execute_reply":"2024-04-28T08:57:35.786471Z","shell.execute_reply.started":"2024-04-28T07:28:47.790717Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [07:06<00:00,  2.79batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/18 Loss: 1.1024 Acc: 0.6113\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:57<00:00,  3.99batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/18 Loss: 1.0281 Acc: 0.6333\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:52<00:00,  4.06batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/18 Loss: 1.0037 Acc: 0.6416\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:49<00:00,  4.10batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/18 Loss: 0.9932 Acc: 0.6442\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:50<00:00,  4.08batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/18 Loss: 0.9702 Acc: 0.6545\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:57<00:00,  4.00batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/18 Loss: 0.9610 Acc: 0.6552\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:49<00:00,  4.11batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/18 Loss: 0.9516 Acc: 0.6580\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:47<00:00,  4.13batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/18 Loss: 0.9518 Acc: 0.6569\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:46<00:00,  4.15batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/18 Loss: 0.9482 Acc: 0.6586\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:46<00:00,  4.14batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/18 Loss: 0.9324 Acc: 0.6628\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:46<00:00,  4.14batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/18 Loss: 0.9201 Acc: 0.6655\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:44<00:00,  4.17batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/18 Loss: 0.9194 Acc: 0.6661\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:44<00:00,  4.18batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/18 Loss: 0.9146 Acc: 0.6678\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:44<00:00,  4.17batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/18 Loss: 0.9068 Acc: 0.6715\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:44<00:00,  4.18batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/18 Loss: 0.9047 Acc: 0.6726\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:45<00:00,  4.16batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/18 Loss: 0.8914 Acc: 0.6762\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:48<00:00,  4.12batch/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/18 Loss: 0.9014 Acc: 0.6760\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1188/1188 [04:45<00:00,  4.16batch/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/18 Loss: 0.8963 Acc: 0.6752\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","        \n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data.\n","        with tqdm(dataloader, unit=\"batch\") as tepoch:\n","            for inputs, labels in tepoch:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # Zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # Forward\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                #print('a')\n","                loss = criterion(outputs, labels)\n","\n","                # Backward + optimize\n","                loss.backward()\n","                optimizer.step()\n","\n","                # Statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","        \n","        epoch_loss = running_loss / len(dataloader.dataset)\n","        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n","\n","        print(f'Epoch {epoch + 1}/{num_epochs} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    return model\n","\n","# Call the training function\n","model = train_model(model, dataloader, criterion, optimizer, num_epochs=18)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T08:57:35.788855Z","iopub.status.busy":"2024-04-28T08:57:35.788580Z","iopub.status.idle":"2024-04-28T08:57:35.796110Z","shell.execute_reply":"2024-04-28T08:57:35.795096Z","shell.execute_reply.started":"2024-04-28T08:57:35.788832Z"},"trusted":true},"outputs":[],"source":["class TestImageDataset(Dataset):\n","    def __init__(self, img_dir, transform=None):\n","        self.img_dir = img_dir\n","        self.image_files = os.listdir(img_dir)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.image_files[idx])\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, self.image_files[idx]  # Return image and its ID\n","\n","# Define transforms\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":17,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T08:57:35.797635Z","iopub.status.busy":"2024-04-28T08:57:35.797322Z","iopub.status.idle":"2024-04-28T08:57:36.017828Z","shell.execute_reply":"2024-04-28T08:57:36.017107Z","shell.execute_reply.started":"2024-04-28T08:57:35.797612Z"},"trusted":true},"outputs":[],"source":["test_dataset = TestImageDataset(img_dir='/kaggle/input/ima205-challenge-2024/Test/Test', transform=transform)\n","\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T08:57:36.019170Z","iopub.status.busy":"2024-04-28T08:57:36.018869Z","iopub.status.idle":"2024-04-28T09:00:41.246949Z","shell.execute_reply":"2024-04-28T09:00:41.245976Z","shell.execute_reply.started":"2024-04-28T08:57:36.019147Z"},"trusted":true},"outputs":[],"source":["model.eval()  # Set model to evaluation mode\n","predictions = []\n","\n","with torch.no_grad():\n","    for image, image_id in test_dataloader:\n","        image = image.to(device)\n","        outputs = model(image)\n","        _, predicted = torch.max(outputs, 1)\n","        predicted_class = predicted.item() + 1  # Since we shifted labels to start from 0\n","        predictions.append((image_id[0], predicted_class))  # Append (image_id, predicted_class) tuple\n","\n","# Write predictions to CSV file\n","submission_df = pd.DataFrame(predictions, columns=['ID', 'CLASS'])\n","submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2024-04-28T09:05:50.279082Z","iopub.status.busy":"2024-04-28T09:05:50.278466Z","iopub.status.idle":"2024-04-28T09:05:50.298480Z","shell.execute_reply":"2024-04-28T09:05:50.297668Z","shell.execute_reply.started":"2024-04-28T09:05:50.279050Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files in output directory:\n","['.virtual_documents', 'submission.csv']\n","\n","Download the submission.csv file:\n","[submission.csv](./submission.csv)\n"]}],"source":["submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n","\n","output_dir = '/kaggle/working/'\n","\n","# List files in the output directory\n","print(\"Files in output directory:\")\n","print(os.listdir(output_dir))\n","\n","# Provide a link to download the submission.csv file\n","print(\"\\nDownload the submission.csv file:\")\n","print(f\"[submission.csv](./submission.csv)\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7803547,"sourceId":70775,"sourceType":"competition"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]"},"vscode":{"interpreter":{"hash":"27058b3c39ded160124dddf25c10a2980fb1f9d0825ab29e2a6cb21d2ffbe03c"}}},"nbformat":4,"nbformat_minor":4}
